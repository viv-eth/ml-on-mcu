{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC feature extraction and Network training\n",
    "\n",
    "In this notebook you will go through an example flow of processing audio data, complete with feature extraction and training.\n",
    "\n",
    "Make sure you read the instructions on the exercise sheet and follow the task order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 14:06:34.977587: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-18 14:06:35.475249: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-18 14:06:35.478248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 14:06:37.134227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  50659\n",
      "Number of test samples:  23072\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "DataSetPath = \"/home/thomas/Documents/ml_mcu/hey_snips_research_6k_en_train_eval_clean_ter/\"\n",
    "\n",
    "with open(DataSetPath+\"train.json\") as jsonfile:\n",
    "    traindata = json.load(jsonfile)\n",
    "\n",
    "with open(DataSetPath+\"test.json\") as jsonfile:\n",
    "    testdata = json.load(jsonfile)\n",
    "\n",
    "print(\"Number of training samples: \", len(traindata))\n",
    "print(\"Number of test samples: \", len(testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: load_data\n",
    "--------------------\n",
    "Loads the dataset and returns the training and testing data as numpy arrays\n",
    "Initializes the training and testing data as lists, then iterates over the\n",
    "training and testing data and appends the data to the lists. The data is\n",
    "segmented into 1024 sample segments with 0 overlap. The data is then zero\n",
    "stuffed to a length of 10 seconds. The data is then converted to a tensor and\n",
    "returned. TQDM is used to display a progress bar.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    totalSliceLength = 10 # Length to stuff the signals to, given in seconds\n",
    "\n",
    "    # Load the full dataset, this will take a while\n",
    "    # trainsize = len(traindata) # Number of loaded training samples\n",
    "    # testsize = len(testdata) # Number of loaded testing samples\n",
    "\n",
    "    # Load a subset of the dataset, this will be much faster\n",
    "    trainsize = 1000 # Number of loaded training samples\n",
    "    testsize = 100 # Number of loaded testing samples\n",
    "\n",
    "    fs = 16000 # Sampling rate of the samples\n",
    "    segmentLength = 1024 # Number of samples to use per segment\n",
    "\n",
    "    # the slice length corresponds to the total length of the signal in seconds\n",
    "    sliceLength = int(totalSliceLength * fs / segmentLength)*segmentLength\n",
    "\n",
    "    for i in tqdm(range(trainsize)): \n",
    "        fs, train_sound_data = wavfile.read(DataSetPath+traindata[i]['audio_file_path']) # Read wavfile to extract amplitudes\n",
    "\n",
    "        _x_train = train_sound_data.copy() # Get a mutable copy of the wavfile\n",
    "        _x_train.resize(sliceLength) # Zero stuff the single to a length of sliceLength\n",
    "        _x_train = _x_train.reshape(-1,int(segmentLength)) # Split slice into Segments with 0 overlap\n",
    "        x_train_list.append(_x_train.astype(np.float32)) # Add segmented slice to training sample list, cast to float so librosa doesn't complain\n",
    "        y_train_list.append(traindata[i]['is_hotword']) # Read label \n",
    "\n",
    "    for i in tqdm(range(testsize)):\n",
    "        fs, test_sound_data = wavfile.read(DataSetPath+testdata[i]['audio_file_path'])\n",
    "        _x_test = test_sound_data.copy()\n",
    "        _x_test.resize(sliceLength)\n",
    "        _x_test = _x_test.reshape((-1,int(segmentLength)))\n",
    "        x_test_list.append(_x_test.astype(np.float32))\n",
    "        y_test_list.append(testdata[i]['is_hotword'])\n",
    "\n",
    "    x_train = tf.convert_to_tensor(np.asarray(x_train_list))\n",
    "    y_train = tf.convert_to_tensor(np.asarray(y_train_list))\n",
    "\n",
    "    x_test = tf.convert_to_tensor(np.asarray(x_test_list))\n",
    "    y_test = tf.convert_to_tensor(np.asarray(y_test_list))\n",
    "\n",
    "    # Printing the shapes is useful to see if the data is loaded correctly\n",
    "    # and gives you an idea how to set the parameters for the model properly\n",
    "    print(\"Training data shape: \", x_train.shape)\n",
    "    print(\"Training labels shape: \", y_train.shape)\n",
    "    print(\"Testing data shape: \", x_test.shape)\n",
    "    print(\"Testing labels shape: \", y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: compute_mfccs\n",
    "-----------------------\n",
    "Computes the MFCCs of the input tensor. The MFCCs are computed using the\n",
    "following parameters:\n",
    "    sample_rate = 16000.0 \n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80 (Mel filterbank)\n",
    "    frame_length = 1024 (1024 samples per frame)\n",
    "    num_mfcc = 13 (13 MFCCs)\n",
    "\"\"\"\n",
    "def compute_mfccs(tensor):\n",
    "    sample_rate = 16000.0\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80\n",
    "    frame_length = 1024\n",
    "    num_mfcc = 13\n",
    "\n",
    "    stfts = tf.signal.stft(tensor, frame_length=frame_length, frame_step=frame_length, fft_length=frame_length)\n",
    "    spectrograms = tf.abs(stfts)\n",
    "    spectrograms = tf.reshape(spectrograms, (spectrograms.shape[0],spectrograms.shape[1],-1))\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n",
    "      upper_edge_hertz)\n",
    "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :num_mfcc]\n",
    "    return tf.reshape(mfccs, (mfccs.shape[0],mfccs.shape[1],mfccs.shape[2],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:02<00:00, 344.89it/s]\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 218.30it/s]\n",
      "2024-03-18 14:06:57.330515: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 638976000 exceeds 10% of free system memory.\n",
      "2024-03-18 14:06:59.501003: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 63897600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (1000, 156, 1024)\n",
      "Training labels shape:  (1000,)\n",
      "Testing data shape:  (100, 156, 1024)\n",
      "Testing labels shape:  (100,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "x_train, y_train, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 156, 13, 1)\n",
      "(100, 156, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_mfcc = compute_mfccs(x_train)\n",
    "x_test_mfcc = compute_mfccs(x_test)\n",
    "\n",
    "\n",
    "print(x_train_mfcc.shape)\n",
    "print(x_test_mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8112000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_train = x_train_mfcc.numpy()\n",
    "np_x_train = np_x_train.reshape((1000, 156, 13))\n",
    "np_x_train.nbytes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training data size without compression:  638976000\n",
      "Total training data size with compression:  8112000\n",
      "Compression ratio:  78.76923076923077\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the compression ratio between the original data and the MFCCs\n",
    "import sys\n",
    "total_train_size_no_compression = x_train.numpy().nbytes\n",
    "total_train_size_with_compression = x_train.numpy().nbytes\n",
    "total_train_size_with_compression = np_x_train.nbytes\n",
    "\n",
    "print(\"Total training data size without compression: \", total_train_size_no_compression)\n",
    "print(\"Total training data size with compression: \", total_train_size_with_compression)\n",
    "print(\"Compression ratio: \", total_train_size_no_compression/total_train_size_with_compression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "epochs = 30\n",
    "\n",
    "# we normalize the data to be in the range [0,1]\n",
    "# this is done by dividing by 512 and adding 0.5\n",
    "# this is because the MFCCs are in the range [-512, 512]\n",
    "# and adding 0.5 shifts the range to [0,1]\n",
    "\n",
    "\n",
    "train_set = (x_train_mfcc/512 + 0.5)\n",
    "train_labels = y_train\n",
    "\n",
    "test_set = (x_test_mfcc/512 + 0.5)\n",
    "test_labels = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 2s 8ms/step - loss: 0.3814 - accuracy: 0.8550\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1548 - accuracy: 0.9370\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1061 - accuracy: 0.9580\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0777 - accuracy: 0.9740\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0751 - accuracy: 0.9720\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0458 - accuracy: 0.9850\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9930\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0290 - accuracy: 0.9920\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9910\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - accuracy: 0.9880\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0198 - accuracy: 0.9960\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0126 - accuracy: 0.9990\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9970\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0146 - accuracy: 0.9950\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.9970\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9980\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9920\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 7.5625e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 6.1768e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 4.6269e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 4.3732e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7cf772e84400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#model.add(layers.InputLayer(input_shape=(train_set.shape[1],train_set.shape[2],train_set.shape[3]), batch_size=(batchSize)))\n",
    "model.add(layers.Conv2D(filters=3,kernel_size=(3,3),padding=\"same\",input_shape=(train_set[0].shape)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=16,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=48,kernel_size=(3,3),padding='same',strides=(2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(8, kernel_regularizer=(regularizers.l1(0))))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(train_set, y_train, batchSize, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 156, 13, 3)        30        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 156, 13, 3)        12        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 156, 13, 3)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 78, 7, 16)         448       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 78, 7, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 78, 7, 16)         0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 39, 3, 16)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 2, 32)         4640      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 20, 2, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 20, 2, 32)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 10, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 1, 48)          13872     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 5, 1, 48)          192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5, 1, 48)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 48)                0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 392       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19796 (77.33 KB)\n",
      "Trainable params: 19598 (76.55 KB)\n",
      "Non-trainable params: 198 (792.00 Byte)\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "score = model.evaluate(test_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk at location:  /home/thomas/Documents/ta_ml_mcu/Exercise5_FS24/Exercise5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/ml_mcu_ex3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"MFCCmodel.h5\")\n",
    "print(\"Saved model to disk at location: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: TFLite conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd805waam/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd805waam/assets\n",
      "/home/thomas/miniconda3/envs/ml_mcu_ex3/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-03-14 17:33:52.883372: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-03-14 17:33:52.883401: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-03-14 17:33:52.886647: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpd805waam\n",
      "2024-03-14 17:33:52.889667: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-03-14 17:33:52.889683: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpd805waam\n",
      "2024-03-14 17:33:52.902173: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-03-14 17:33:52.905148: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-03-14 17:33:53.019363: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpd805waam\n",
      "2024-03-14 17:33:53.052280: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 165599 microseconds.\n",
      "2024-03-14 17:33:53.175419: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28272"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_set.numpy()\n",
    "test_set = test_set.numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "tflite_model_name = 'MFCC'\n",
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([train_set[i].reshape(1,156,13,1)])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'MFCC'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_conv2d_input:0\n",
      "shape: [  1 156  13   1]\n",
      "type: <class 'numpy.int8'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [1 2]\n",
      "type: <class 'numpy.int8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_name + '.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((len(test_set),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(test_set)):\n",
    "    val_batch = test_set[i]\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of quantized to int8 model is 99.0%\n",
      "Compared to float32 accuracy of 99.00000095367432%\n",
      "We have a change of -9.536743172944284e-07%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 100\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))\n",
    "print(\"Compared to float32 accuracy of {}%\".format(score[1]*100))\n",
    "print(\"We have a change of {}%\".format((accuracy_score-score[1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_mcu_ex3",
   "language": "python",
   "name": "ml_mcu_ex3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
